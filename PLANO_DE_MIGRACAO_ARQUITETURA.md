# Plano de Migra√ß√£o Arquitetural LexHub SaaS

**De:** Monolito Frontend (SPA) + Supabase Direto
**Para:** Arquitetura H√≠brida Orientada a Eventos (EDA) e Microsservi√ßos

Como n√£o h√° usu√°rios reais utilizando a plataforma no momento, podemos fazer uma **migra√ß√£o disruptiva** ("Big Bang Re-architecture"). O objetivo √© preparar o LexHub para suportar dezenas de milhares de requisi√ß√µes simult√¢neas de clientes via WhatsApp e orquestra√ß√£o pesada de Agentes de IA sem comprometer o painel dos advogados (Tenant).

---

## üéØ Vis√£o Geral da Nova Arquitetura

1. **Frontend (BFF):** Mant√©m-se em React/Vite, mas todas as requisi√ß√µes complexas passar√£o por um API Gateway pr√≥prio, n√£o apenas chamadas diretas ao Supabase.
2. **Core API / API Gateway (Node.js + NestJS/Express):** Gerencia assinaturas (Stripe), controle de acesso (RBAC e Tenants), regras de neg√≥cio pesadas e orquestra comunica√ß√£o entre servi√ßos.
3. **Servi√ßo de Mensageria (WhatsApp/Instagram):** Um microsservi√ßo isolado apenas para receber Webhooks da Meta, responder instantaneamente com HTTP 200 (evitando penalidades da Meta) e despachar a mensagem para a fila (Queue).
4. **Message Broker / Filas (Redis + BullMQ ou RabbitMQ):** O "cora√ß√£o" da escalabilidade. Gerenciar√° o tr√°fego de mensagens recebidas e tarefas a serem processadas.
5. **Servi√ßo de Intelig√™ncia Artificial (Workers):** Processos rodando em background consumindo as mensagens da fila. Eles enviam para LLMs (Google GenAI, OpenAI), recebem a resposta assincronamente e colocam o resultado em outra fila para envio.

---

## üìÖ Plano de A√ß√£o Passo a Passo

### Fase 1: Prepara√ß√£o da Infraestrutura & Message Broker
Nesta etapa, preparamos o ambiente para suportar filas e servi√ßos em background.

*   [ ] **1.1 Subir a Infraestrutura Base:** Provisionar servidor Redis (no Coolify, AWS ElastiCache, ou via Docker localmente) para gerenciar as filas.
*   [ ] **1.2 Migra√ß√£o de Scripts de Banco de Dados:** Consolidar todo o schema do banco de dados (Tabelas, pol√≠ticas RLS, Functions) em migrations SQL versionadas via CLI do Supabase.
*   [ ] **1.3 RLS (Row Level Security):** Garantir que TODAS as tabelas do Supabase (`processes`, `clients`, `conversations`) tenham a coluna obrigat√≥ria `tenant_id` e pol√≠ticas RLS impenetr√°veis (onde apenas o token do Tenant correto consiga acessar dados via Frontend).

### Fase 2: Cria√ß√£o do API Gateway (Core Service) e Microsservi√ßo de Webhooks
Desenvolveremos o backend centralizado e o microsservi√ßo para lidar exclusivamente com chamadas de alta vaz√£o.

*   [ ] **2.1 Setup do Projeto API (Node.js/TypeScript):** Criar reposit√≥rio/pasta do Gateway. (Ex: `lexhub-core-api`).
*   [ ] **2.2 Migra√ß√£o do Stripe e L√≥gica de Neg√≥cios:** Mover toda a l√≥gica de checkout do Stripe, Webhooks de faturamento, gerenciamento de Tenants (suspens√£o/ativa√ß√£o) para o Core API.
*   [ ] **2.3 Microsservi√ßo de Webhooks (Omnichannel API):** Criar API super enxuta. O √∫nico papel deste servi√ßo √© ouvir `/webhooks/meta`, autenticar a requisi√ß√£o, empacotar os dados (telefone, mensagem do contato) e enfileirar no Redis (BullMQ: Job `whatsapp-message-received`), retornando c√≥digo HTTP 200 pro Meta na mesma hora.

### Fase 3: Worker Service de Intelig√™ncia Artificial (Servi√ßo de Processamento Pesado)
Este √© o servi√ßo que executa tarefas demoradas e n√£o pode bloquear a UI. Pode ser feito em NodeJS ou Python.

*   [ ] **3.1 Criar o AI Worker Component:** Setup do worker que escuta a fila do Redis (`whatsapp-message-received`).
*   [ ] **3.2 Integra√ß√£o com LLMs SDK & Contexto:** O Worker vai desempacotar a Job e rodar o fluxo de IA: 
    *   Fazer fetch ass√≠ncrono do perfil do `Agent IA` daquele Tenant.
    *   Pegar o hist√≥rico das √∫ltimas N mensagens daquele contato (Supabase).
    *   Enviar o prompt completo + RAG pro Google GenAI/OpenAI.
*   [ ] **3.3 Fila de Resposta (Sa√≠da):** Com a resposta gerada da IA pronta, enfileirar um novo Job (`send-whatsapp-message`) com o texto. O Microsservi√ßo Omnichannel (Fase 2) processa o envio de volta ao Meta. Salvar tudo no DB assincronamente.

### Fase 4: O Workflow de Automa√ß√£o Interna
Aplicativo de UI precisa enviar fluxos pesados para o backend em vez de travar o navegador.

*   [ ] **4.1 Criar Fila de Gera√ß√£o de Documentos:** Criar fila gen√©rica `document-generation`.
*   [ ] **4.2 Migra√ß√£o da L√≥gica Local:** Transformar as requisi√ß√µes de IA feitas hoje diretamente pelo React (no painel "M√≥dulo IA") em requisi√ß√µes ass√≠ncronas POST para o Core API. 
*   [ ] **4.3 Realtime Push (WebSockets/Supabase Realtime):** Quando a IA/Worker terminar a gera√ß√£o do documento em background, atualizar uma linha no banco do Supabase e disparar um evento (Supabase Realtime) sinalizando ao Painel SPA do usu√°rio (React) que a tarefa terminou (mostrando o toast verde).

### Fase 5: Refatora√ß√£o do Frontend (SPA React/Vite)
Desconectar o frontend de chamadas complexas diretas ao banco de dados e plug√°-lo no Gateway/Eventos.

*   [ ] **5.1 Substitui√ß√£o dos SDKs Lentos:** Trocar as gera√ß√µes s√≠ncronas de IA no frontend (`@google/genai` n√£o deve estar rodando no Browser do usu√°rio) por chamadas de API (`POST /api/agents/chat/enqueue`).
*   [ ] **5.2 Assinatura Realtime Global:** Implementar o listener do Supabase Realtime no n√≠vel do contexto `App.tsx` para monitorar "jobs finalizados". Assim que o banco sinalizar conclus√£o, um Alert ou Toast global deve notificar o advogado de que a triagem, o peticionamento, ou o resumo est√° pronto.
*   [ ] **5.3 Limpeza:** Remover todo c√≥digo do arquivo `aiTools.ts` do Frontend para o servi√ßo de Worker do Backend.

### Fase 6: Deploy & Orquestra√ß√£o
*   [ ] **6.1 Dockeriza√ß√£o:** Criar `Dockerfile`s distintos para: 
    1) Frontend (Dist do Vite/Nginx). 
    2) Core API Gateway. 
    3) Omnichannel Microservice (Fastify/Express). 
    4) AI Worker Service (NodeJS/Python puro).
*   [ ] **6.2 Compose/Orquestrador (Coolify):** Configurar no Coolify o mapeamento e cria√ß√£o destes containeres com escalabilidade cruzada de Workers.
*   [ ] **6.3 Monitoramento Base:** Setup de logs (como Sentry ou ELK) centralizado nos Workers, pois quando erros ocorrem soltos em Filas no backend, eles s√£o silenciosos e o frontend n√£o ficar√° sabendo.

---

## ‚ö° Benef√≠cios Imediatos ap√≥s Migra√ß√£o (O Impacto da Escala)
*   **Zero Concurrency Blocking:** M√∫ltiplos processos simult√¢neos acontecendo no mesmo momento (e.g., dezenas de mensagens do Instagram + Webhooks + 3 advogados pedindo resumo de peti√ß√£o) enfileiram silenciosamente, sendo processados controladamente, sem pico exaustivo de gargalo.
*   **Toler√¢ncia a Falhas Segura (Dead Letter Queues):** Se a AI falhar por timeout da OpenAI/Gemini, o Worker de IA coloca o Job de volta no final da fila para retry autom√°tico. O usu√°rio frontend n√£o perde o dado.
*   **Security (Frontend Dummy):** O client React fica mais enxuto e estrito: s√≥ exibe dados ou faz dispatches. As regras de neg√≥cio confidenciais tornam-se inalcan√ß√°veis via ferramentas de desenvolvedor do navegador.
